{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ! conda install -q -y -c conda-forge spacy\n",
    "# ! conda install -q -y -c anaconda nltk\n",
    "# ! python -m spacy download en_core_web_md\n",
    "# ! python -m spacy download es_core_news_md\n",
    "# ! pip install --quiet langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score, make_scorer, recall_score, precision_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, VectorizerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from re import sub, split, findall\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import strip_accents_unicode\n",
    "\n",
    "def clean_html(s):\n",
    "    \"\"\" Converts all HTML elements to Unicode \"\"\"\n",
    "    try:\n",
    "        s = sub(r'https?://[^\\s]+', '', s)\n",
    "        s = sub(r'@\\w+', '', s) #remove @'s from tweets\n",
    "        return BeautifulSoup(s, 'html5lib').get_text() if s else ''\n",
    "    except UserWarning:\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return ''\n",
    "\n",
    "def split_numbers(s):\n",
    "    return ' '.join(split('(\\d+)[^\\d\\s]+', s))\n",
    "\n",
    "def round_numbers(m, lim = 300):\n",
    "    n = int(m.group(1))\n",
    "    if n < 1:\n",
    "        return ''\n",
    "    if n < lim:\n",
    "        return 'SMALLNUMBER'\n",
    "    else:\n",
    "        return 'LARGENUMBER'\n",
    "\n",
    "def tokenize_numbers(s):\n",
    "    return sub('(\\d+)', round_numbers, s)\n",
    "\n",
    "def tokenize_short(s, lim = 5):\n",
    "    token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    tokens = token_pattern.findall(s)\n",
    "    if (len(tokens) < lim):\n",
    "        return 'SHORTARTICLE ' + s\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def format_numbers(s):\n",
    "    decomma = lambda m: m.group(1) + m.group(2)\n",
    "    s = sub('(\\d+),(\\d+)', decomma, s)\n",
    "    return s\n",
    "\n",
    "def preprocessor(s):\n",
    "    s = clean_html(s)\n",
    "    s = format_numbers(s)\n",
    "    s = split_numbers(s)\n",
    "    s = tokenize_numbers(s)\n",
    "    s = strip_accents_unicode(s.lower())\n",
    "    s = tokenize_short(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from sklearn.feature_extraction.text import VectorizerMixin\n",
    "\n",
    "def ngrammer(tokens, ngram_range):\n",
    "    mix = VectorizerMixin()    \n",
    "    mix.ngram_range = ngram_range\n",
    "    return mix._word_ngrams(tokens)\n",
    "\n",
    "def analyzer(s, ngram_range = (1,2)):\n",
    "    s = preprocessor(s)\n",
    "    if detect(s) != 'en':\n",
    "        pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "        unigrams = pattern.findall(s)    \n",
    "    else:\n",
    "        tokens = nlp(s)\n",
    "        filtered = [t for t in tokens if not t.is_stop and not t.dep_ in ['', 'punct']]\n",
    "        unigrams = [':'.join([t.lemma_, t.dep_]) for t in filtered]\n",
    "    return ngrammer(unigrams, ngram_range)\n",
    "\n",
    "    # tokens = pattern.findall(s)\n",
    "    # with_pos = nltk.pos_tag(tokens)\n",
    "    # return [':'.join(w) for w in with_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('kaggle/train.csv').tweet\n",
    "y_train = pd.read_csv('kaggle/train.csv').label\n",
    "y_test = pd.read_csv('kaggle/solution.csv').label\n",
    "X_test = pd.read_csv('kaggle/test.csv').tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def vectorizer(X_train, X_test, analyzer = analyzer):\n",
    "    idx = X_train.shape[0]\n",
    "    X = pd.concat([X_train, X_test])\n",
    "    vector = TfidfVectorizer(analyzer = analyzer).fit(X).transform(X)\n",
    "    return vector[0:idx], vector[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "V_train, V_test = vectorizer(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# model = MultinomialNB(class_prior = [0.5,0.5])\n",
    "model = base_model()\n",
    "model.fit(V_train, y_train)\n",
    "three_preds = model.predict_proba(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(tol = 10e-6, max_iter = 8000)\n",
    "model.fit(V_train, y_train)\n",
    "three_svc = model.decision_function(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375 0.759493670886 0.839160839161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25974025974025972"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = three_preds > .5\n",
    "print(precision_score(y_test, p), recall_score(y_test, p), f1_score(y_test, p))\n",
    "p.sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869918699187 0.812658227848 0.840314136126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29951298701298701"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = three_svc > -.3\n",
    "# p = three_preds > .5\n",
    "print (precision_score(y_test, p), recall_score(y_test, p), f1_score(y_test, p))\n",
    "p.sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'DT'), ('migrant', 'NN'), ('was', 'VBD'), ('stabbed', 'VBN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.pos_tag('a migrant was stabbed'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sha1:ed21921c94d1:2af52eda4765ea12514f45468fac48418c6c8ec5'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook.auth import passwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
