{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, VectorizerMixin\n",
    "from utils import ngrammer, clean_html, get_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from utils import clean_html\n",
    "from sklearn.feature_extraction.text import strip_accents_unicode\n",
    "\n",
    "def clean_twitter(s):\n",
    "    \"\"\" Cleans Twitter specific issues \n",
    "    \n",
    "    Can you think of what else you might need to add here?\n",
    "    \"\"\"\n",
    "    s = sub(r'@\\w+', '', s) #remove @ mentions from tweets    \n",
    "    return s\n",
    "\n",
    "def preprocessor(s):\n",
    "    \"\"\" For all basic string cleanup. \n",
    "    \n",
    "    Think of what you can add to this to improve things. What is\n",
    "    specific to your goal, how can you transform the text. Add tokens,\n",
    "    remove things, unify things. \n",
    "    \"\"\"\n",
    "    s = clean_html(s)\n",
    "    s = strip_accents_unicode(s.lower())\n",
    "    s = clean_twitter(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "def analyzer(s, ngram_range = (1,2)):\n",
    "    \"\"\" Does everything to turn raw documents into tokens.  \n",
    "    \n",
    "    Note: None of the above tokenizers are implemented!\n",
    "    \"\"\"\n",
    "    s = preprocessor(s)\n",
    "    pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    unigrams = pattern.findall(s)\n",
    "    unigrams = [u for u in unigrams if u not in ENGLISH_STOP_WORDS]\n",
    "    tokens = ngrammer(unigrams, ngram_range)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('kaggle/train.csv').tweet\n",
    "y = pd.read_csv('kaggle/train.csv').label\n",
    "\n",
    "cutoff = 1750\n",
    "X_train, X_test, y_train, y_test = X[0:cutoff], X[cutoff:], y[0:cutoff], y[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Turn the text data into a fixed-length vectors that can be used to train a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SKLearn's Logistic Regression allows us to use an L1 \n",
    "# penalty, turning it into a Lasso classifier.\n",
    "\n",
    "# What does the C parameter do, according to the documentation? \n",
    "lasso = LogisticRegression(penalty='l1', C=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Make your predictions for the test set (X_test/y_test)\n",
    "\n",
    "preds = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Take a look at the mistakes\n",
    "\n",
    "false_pos, false_neg = get_errors(X_test, y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-1",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "migrants.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
